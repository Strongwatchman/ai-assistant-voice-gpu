[
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/cc -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -o CMakeFiles/ggml-base.dir/ggml.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml.c",
  "output": "ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/ggml-base.dir/ggml.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml.cpp",
  "output": "ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/cc -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -o CMakeFiles/ggml-base.dir/ggml-alloc.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-alloc.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-alloc.c",
  "output": "ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/ggml-base.dir/ggml-backend.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-backend.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-backend.cpp",
  "output": "ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/ggml-base.dir/ggml-opt.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-opt.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-opt.cpp",
  "output": "ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/ggml-base.dir/ggml-threading.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-threading.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-threading.cpp",
  "output": "ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/cc -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -o CMakeFiles/ggml-base.dir/ggml-quants.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-quants.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-quants.c",
  "output": "ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/ggml-base.dir/gguf.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/gguf.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/gguf.cpp",
  "output": "ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/cc -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/repack.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/repack.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/hbm.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/hbm.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/cc -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/quants.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/quants.c",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/traits.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/traits.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/amx/amx.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/amx/amx.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/amx/mmq.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/amx/mmq.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/binary-ops.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/binary-ops.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/unary-ops.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/unary-ops.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/vec.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/vec.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/ops.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/ops.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/llamafile/sgemm.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/llamafile/sgemm.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/cc -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/arch/x86/quants.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/arch/x86/quants.c",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/.. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -march=native -fopenmp -o CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/arch/x86/repack.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cpu/arch/x86/repack.cpp",
  "output": "ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-backend-reg.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-backend-reg.cpp",
  "output": "ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/acc.cu -o CMakeFiles/ggml-cuda.dir/acc.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/acc.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/acc.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/arange.cu -o CMakeFiles/ggml-cuda.dir/arange.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/arange.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/arange.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/argmax.cu -o CMakeFiles/ggml-cuda.dir/argmax.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/argmax.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argmax.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/argsort.cu -o CMakeFiles/ggml-cuda.dir/argsort.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/argsort.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/argsort.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/binbcast.cu -o CMakeFiles/ggml-cuda.dir/binbcast.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/binbcast.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/binbcast.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/clamp.cu -o CMakeFiles/ggml-cuda.dir/clamp.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/clamp.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/clamp.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/concat.cu -o CMakeFiles/ggml-cuda.dir/concat.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/concat.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/concat.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/conv-transpose-1d.cu -o CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/conv-transpose-1d.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv-transpose-1d.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/conv2d-dw.cu -o CMakeFiles/ggml-cuda.dir/conv2d-dw.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/conv2d-dw.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-dw.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/conv2d-transpose.cu -o CMakeFiles/ggml-cuda.dir/conv2d-transpose.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/conv2d-transpose.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/conv2d-transpose.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/convert.cu -o CMakeFiles/ggml-cuda.dir/convert.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/convert.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/convert.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/count-equal.cu -o CMakeFiles/ggml-cuda.dir/count-equal.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/count-equal.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/count-equal.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/cpy.cu -o CMakeFiles/ggml-cuda.dir/cpy.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/cpy.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cpy.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/cross-entropy-loss.cu -o CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/cross-entropy-loss.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/cross-entropy-loss.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/diagmask.cu -o CMakeFiles/ggml-cuda.dir/diagmask.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/diagmask.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/diagmask.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f16.cu -o CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f32.cu -o CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f32.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-tile-f32.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/fattn-wmma-f16.cu -o CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/fattn-wmma-f16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn-wmma-f16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/fattn.cu -o CMakeFiles/ggml-cuda.dir/fattn.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/fattn.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/fattn.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/getrows.cu -o CMakeFiles/ggml-cuda.dir/getrows.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/getrows.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/getrows.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/ggml-cuda.cu -o CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/ggml-cuda.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ggml-cuda.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/gla.cu -o CMakeFiles/ggml-cuda.dir/gla.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/gla.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/gla.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/im2col.cu -o CMakeFiles/ggml-cuda.dir/im2col.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/im2col.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/im2col.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/mean.cu -o CMakeFiles/ggml-cuda.dir/mean.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/mean.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mean.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/mmq.cu -o CMakeFiles/ggml-cuda.dir/mmq.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/mmq.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmq.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/mmv.cu -o CMakeFiles/ggml-cuda.dir/mmv.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/mmv.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmv.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/mmvq.cu -o CMakeFiles/ggml-cuda.dir/mmvq.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/mmvq.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/mmvq.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/norm.cu -o CMakeFiles/ggml-cuda.dir/norm.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/norm.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/norm.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/opt-step-adamw.cu -o CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/opt-step-adamw.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/opt-step-adamw.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/out-prod.cu -o CMakeFiles/ggml-cuda.dir/out-prod.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/out-prod.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/out-prod.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/pad.cu -o CMakeFiles/ggml-cuda.dir/pad.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/pad.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pad.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/pool2d.cu -o CMakeFiles/ggml-cuda.dir/pool2d.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/pool2d.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/pool2d.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/quantize.cu -o CMakeFiles/ggml-cuda.dir/quantize.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/quantize.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/quantize.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/rope.cu -o CMakeFiles/ggml-cuda.dir/rope.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/rope.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/rope.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/scale.cu -o CMakeFiles/ggml-cuda.dir/scale.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/scale.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/scale.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/softmax.cu -o CMakeFiles/ggml-cuda.dir/softmax.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/softmax.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/softmax.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/ssm-conv.cu -o CMakeFiles/ggml-cuda.dir/ssm-conv.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/ssm-conv.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-conv.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/ssm-scan.cu -o CMakeFiles/ggml-cuda.dir/ssm-scan.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/ssm-scan.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/ssm-scan.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/sum.cu -o CMakeFiles/ggml-cuda.dir/sum.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/sum.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sum.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/sumrows.cu -o CMakeFiles/ggml-cuda.dir/sumrows.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/sumrows.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/sumrows.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/tsembd.cu -o CMakeFiles/ggml-cuda.dir/tsembd.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/tsembd.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/tsembd.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/unary.cu -o CMakeFiles/ggml-cuda.dir/unary.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/unary.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/unary.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/upscale.cu -o CMakeFiles/ggml-cuda.dir/upscale.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/upscale.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/upscale.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/wkv.cu -o CMakeFiles/ggml-cuda.dir/wkv.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/wkv.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/wkv.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq1_s.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_s.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xs.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq2_xxs.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_s.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq3_xxs.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_nl.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-iq4_xs.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q2_k.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q3_k.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_0.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_1.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q4_k.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_0.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_1.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q5_k.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q6_k.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/mmq-instance-q8_0.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/ggml/src/ggml-cuda",
  "command": "/usr/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cuda_EXPORTS --options-file CMakeFiles/ggml-cuda.dir/includes_CUDA.rsp -O3 -DNDEBUG -std=c++17 \"--generate-code=arch=compute_86,code=[compute_86,sm_86]\" -Xcompiler=-fPIC -use_fast_math -extended-lambda -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-pedantic\" -x cu -c /home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu -o CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu",
  "output": "ggml/src/ggml-cuda/CMakeFiles/ggml-cuda.dir/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama.cpp",
  "output": "src/CMakeFiles/llama.dir/llama.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-adapter.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-adapter.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-adapter.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-adapter.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-arch.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-arch.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-arch.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-arch.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-batch.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-batch.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-batch.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-batch.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-chat.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-chat.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-chat.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-chat.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-context.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-context.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-context.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-context.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-cparams.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-cparams.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-cparams.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-cparams.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-grammar.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-grammar.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-grammar.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-grammar.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-graph.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-graph.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-graph.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-graph.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-hparams.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-hparams.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-hparams.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-hparams.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-impl.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-impl.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-impl.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-impl.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-io.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-io.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-io.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-io.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-kv-cache-unified.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-kv-cache-unified.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-kv-cache-unified.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-kv-cache-unified.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-kv-cache-unified-iswa.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-kv-cache-unified-iswa.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-kv-cache-unified-iswa.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-kv-cache-unified-iswa.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-memory.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-memory.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-memory.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-memory.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-memory-hybrid.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-memory-hybrid.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-memory-recurrent.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-memory-recurrent.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-mmap.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-mmap.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-mmap.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-mmap.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-model-loader.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-model-loader.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-model-loader.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-model-loader.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-model-saver.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-model-saver.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-model-saver.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-model-saver.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-model.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-quant.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-quant.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-quant.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-quant.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-sampling.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-sampling.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-sampling.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-sampling.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/llama-vocab.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/llama-vocab.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/llama-vocab.cpp",
  "output": "src/CMakeFiles/llama.dir/llama-vocab.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/unicode-data.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/unicode-data.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/unicode-data.cpp",
  "output": "src/CMakeFiles/llama.dir/unicode-data.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/src",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/src/. -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama.dir/unicode.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/src/unicode.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/src/unicode.cpp",
  "output": "src/CMakeFiles/llama.dir/unicode.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++   -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/build_info.dir/build-info.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/build/common/build-info.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common/build-info.cpp",
  "output": "common/CMakeFiles/build_info.dir/build-info.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/arg.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/arg.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/arg.cpp",
  "output": "common/CMakeFiles/common.dir/arg.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/chat-parser.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/chat-parser.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/chat-parser.cpp",
  "output": "common/CMakeFiles/common.dir/chat-parser.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/chat.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/chat.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/chat.cpp",
  "output": "common/CMakeFiles/common.dir/chat.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/common.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/common.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/common.cpp",
  "output": "common/CMakeFiles/common.dir/common.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/console.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/console.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/console.cpp",
  "output": "common/CMakeFiles/common.dir/console.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/json-partial.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/json-partial.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/json-partial.cpp",
  "output": "common/CMakeFiles/common.dir/json-partial.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/json-schema-to-grammar.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/json-schema-to-grammar.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/json-schema-to-grammar.cpp",
  "output": "common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/llguidance.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/llguidance.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/llguidance.cpp",
  "output": "common/CMakeFiles/common.dir/llguidance.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/log.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/log.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/log.cpp",
  "output": "common/CMakeFiles/common.dir/log.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/ngram-cache.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/ngram-cache.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/ngram-cache.cpp",
  "output": "common/CMakeFiles/common.dir/ngram-cache.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/regex-partial.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/regex-partial.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/regex-partial.cpp",
  "output": "common/CMakeFiles/common.dir/regex-partial.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/sampling.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/sampling.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/sampling.cpp",
  "output": "common/CMakeFiles/common.dir/sampling.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/common",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/common.dir/speculative.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/common/speculative.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/common/speculative.cpp",
  "output": "common/CMakeFiles/common.dir/speculative.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-tokenizer-0.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-tokenizer-0.cpp",
  "output": "tests/CMakeFiles/test-tokenizer-0.dir/test-tokenizer-0.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-sampling.dir/test-sampling.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-sampling.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-sampling.cpp",
  "output": "tests/CMakeFiles/test-sampling.dir/test-sampling.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-sampling.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-sampling.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-grammar-parser.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-grammar-parser.cpp",
  "output": "tests/CMakeFiles/test-grammar-parser.dir/test-grammar-parser.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-grammar-parser.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-grammar-parser.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-grammar-integration.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-grammar-integration.cpp",
  "output": "tests/CMakeFiles/test-grammar-integration.dir/test-grammar-integration.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-grammar-integration.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-grammar-integration.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-llama-grammar.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-llama-grammar.cpp",
  "output": "tests/CMakeFiles/test-llama-grammar.dir/test-llama-grammar.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-llama-grammar.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-llama-grammar.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-chat.dir/test-chat.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-chat.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-chat.cpp",
  "output": "tests/CMakeFiles/test-chat.dir/test-chat.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-chat.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-chat.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/server -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-json-schema-to-grammar.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-json-schema-to-grammar.cpp",
  "output": "tests/CMakeFiles/test-json-schema-to-grammar.dir/test-json-schema-to-grammar.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/server -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-json-schema-to-grammar.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-quantize-stats.dir/test-quantize-stats.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-quantize-stats.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-quantize-stats.cpp",
  "output": "tests/CMakeFiles/test-quantize-stats.dir/test-quantize-stats.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-gbnf-validator.dir/test-gbnf-validator.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-gbnf-validator.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-gbnf-validator.cpp",
  "output": "tests/CMakeFiles/test-gbnf-validator.dir/test-gbnf-validator.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-tokenizer-1-bpe.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-tokenizer-1-bpe.cpp",
  "output": "tests/CMakeFiles/test-tokenizer-1-bpe.dir/test-tokenizer-1-bpe.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-tokenizer-1-spm.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-tokenizer-1-spm.cpp",
  "output": "tests/CMakeFiles/test-tokenizer-1-spm.dir/test-tokenizer-1-spm.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-chat-parser.dir/test-chat-parser.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-chat-parser.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-chat-parser.cpp",
  "output": "tests/CMakeFiles/test-chat-parser.dir/test-chat-parser.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-chat-parser.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-chat-parser.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-chat-template.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-chat-template.cpp",
  "output": "tests/CMakeFiles/test-chat-template.dir/test-chat-template.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-chat-template.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-chat-template.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-json-partial.dir/test-json-partial.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-json-partial.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-json-partial.cpp",
  "output": "tests/CMakeFiles/test-json-partial.dir/test-json-partial.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-json-partial.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-json-partial.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-log.dir/test-log.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-log.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-log.cpp",
  "output": "tests/CMakeFiles/test-log.dir/test-log.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-log.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-log.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-regex-partial.dir/test-regex-partial.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-regex-partial.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-regex-partial.cpp",
  "output": "tests/CMakeFiles/test-regex-partial.dir/test-regex-partial.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-regex-partial.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-regex-partial.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-thread-safety.dir/test-thread-safety.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-thread-safety.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-thread-safety.cpp",
  "output": "tests/CMakeFiles/test-thread-safety.dir/test-thread-safety.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-thread-safety.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-thread-safety.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-arg-parser.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-arg-parser.cpp",
  "output": "tests/CMakeFiles/test-arg-parser.dir/test-arg-parser.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-arg-parser.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-arg-parser.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-gguf.dir/test-gguf.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-gguf.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-gguf.cpp",
  "output": "tests/CMakeFiles/test-gguf.dir/test-gguf.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-gguf.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-gguf.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-backend-ops.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-backend-ops.cpp",
  "output": "tests/CMakeFiles/test-backend-ops.dir/test-backend-ops.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-backend-ops.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-backend-ops.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-model-load-cancel.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-model-load-cancel.cpp",
  "output": "tests/CMakeFiles/test-model-load-cancel.dir/test-model-load-cancel.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-model-load-cancel.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-autorelease.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-autorelease.cpp",
  "output": "tests/CMakeFiles/test-autorelease.dir/test-autorelease.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-autorelease.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-autorelease.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-barrier.dir/test-barrier.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-barrier.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-barrier.cpp",
  "output": "tests/CMakeFiles/test-barrier.dir/test-barrier.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-barrier.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-barrier.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-quantize-fns.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-quantize-fns.cpp",
  "output": "tests/CMakeFiles/test-quantize-fns.dir/test-quantize-fns.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-quantize-fns.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-quantize-fns.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-quantize-perf.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-quantize-perf.cpp",
  "output": "tests/CMakeFiles/test-quantize-perf.dir/test-quantize-perf.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-quantize-perf.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-quantize-perf.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-rope.dir/test-rope.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-rope.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-rope.cpp",
  "output": "tests/CMakeFiles/test-rope.dir/test-rope.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-rope.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-rope.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/cc -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/. -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -o CMakeFiles/test-mtmd-c-api.dir/test-mtmd-c-api.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-mtmd-c-api.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-mtmd-c-api.c",
  "output": "tests/CMakeFiles/test-mtmd-c-api.dir/test-mtmd-c-api.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/. -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/test-mtmd-c-api.dir/get-model.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/get-model.cpp",
  "output": "tests/CMakeFiles/test-mtmd-c-api.dir/get-model.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tests",
  "command": "/usr/bin/cc -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -o CMakeFiles/test-c.dir/test-c.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tests/test-c.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tests/test-c.c",
  "output": "tests/CMakeFiles/test-c.dir/test-c.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/batched",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-batched.dir/batched.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/batched/batched.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/batched/batched.cpp",
  "output": "examples/batched/CMakeFiles/llama-batched.dir/batched.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/embedding",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-embedding.dir/embedding.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/embedding/embedding.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/embedding/embedding.cpp",
  "output": "examples/embedding/CMakeFiles/llama-embedding.dir/embedding.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/eval-callback",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/eval-callback/eval-callback.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/eval-callback/eval-callback.cpp",
  "output": "examples/eval-callback/CMakeFiles/llama-eval-callback.dir/eval-callback.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/gguf-hash",
  "command": "/usr/bin/cc  -I/home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/deps -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -o CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/deps/xxhash/xxhash.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/deps/xxhash/xxhash.c",
  "output": "examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/gguf-hash",
  "command": "/usr/bin/cc  -I/home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/deps -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -w -o CMakeFiles/sha1.dir/deps/sha1/sha1.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/deps/sha1/sha1.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/deps/sha1/sha1.c",
  "output": "examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/gguf-hash",
  "command": "/usr/bin/cc  -I/home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/deps -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -o CMakeFiles/sha256.dir/deps/sha256/sha256.c.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/deps/sha256/sha256.c",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/deps/sha256/sha256.c",
  "output": "examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/gguf-hash",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -I/home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/deps -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/gguf-hash.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf-hash/gguf-hash.cpp",
  "output": "examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/gguf",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-gguf.dir/gguf.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf/gguf.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/gguf/gguf.cpp",
  "output": "examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/gritlm",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-gritlm.dir/gritlm.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/gritlm/gritlm.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/gritlm/gritlm.cpp",
  "output": "examples/gritlm/CMakeFiles/llama-gritlm.dir/gritlm.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/lookahead",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-lookahead.dir/lookahead.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/lookahead/lookahead.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/lookahead/lookahead.cpp",
  "output": "examples/lookahead/CMakeFiles/llama-lookahead.dir/lookahead.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/lookup",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-lookup.dir/lookup.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/lookup/lookup.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/lookup/lookup.cpp",
  "output": "examples/lookup/CMakeFiles/llama-lookup.dir/lookup.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/lookup",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/lookup/lookup-create.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/lookup/lookup-create.cpp",
  "output": "examples/lookup/CMakeFiles/llama-lookup-create.dir/lookup-create.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/lookup",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/lookup/lookup-merge.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/lookup/lookup-merge.cpp",
  "output": "examples/lookup/CMakeFiles/llama-lookup-merge.dir/lookup-merge.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/lookup",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/lookup/lookup-stats.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/lookup/lookup-stats.cpp",
  "output": "examples/lookup/CMakeFiles/llama-lookup-stats.dir/lookup-stats.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/parallel",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-parallel.dir/parallel.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/parallel/parallel.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/parallel/parallel.cpp",
  "output": "examples/parallel/CMakeFiles/llama-parallel.dir/parallel.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/passkey",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-passkey.dir/passkey.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/passkey/passkey.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/passkey/passkey.cpp",
  "output": "examples/passkey/CMakeFiles/llama-passkey.dir/passkey.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/retrieval",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-retrieval.dir/retrieval.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/retrieval/retrieval.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/retrieval/retrieval.cpp",
  "output": "examples/retrieval/CMakeFiles/llama-retrieval.dir/retrieval.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/save-load-state",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/save-load-state/save-load-state.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/save-load-state/save-load-state.cpp",
  "output": "examples/save-load-state/CMakeFiles/llama-save-load-state.dir/save-load-state.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/simple",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-simple.dir/simple.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/simple/simple.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/simple/simple.cpp",
  "output": "examples/simple/CMakeFiles/llama-simple.dir/simple.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/simple-chat",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/simple-chat/simple-chat.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/simple-chat/simple-chat.cpp",
  "output": "examples/simple-chat/CMakeFiles/llama-simple-chat.dir/simple-chat.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/speculative",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-speculative.dir/speculative.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/speculative/speculative.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/speculative/speculative.cpp",
  "output": "examples/speculative/CMakeFiles/llama-speculative.dir/speculative.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/speculative-simple",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/speculative-simple/speculative-simple.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/speculative-simple/speculative-simple.cpp",
  "output": "examples/speculative-simple/CMakeFiles/llama-speculative-simple.dir/speculative-simple.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/gen-docs",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/gen-docs/gen-docs.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/gen-docs/gen-docs.cpp",
  "output": "examples/gen-docs/CMakeFiles/llama-gen-docs.dir/gen-docs.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/training",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-finetune.dir/finetune.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/training/finetune.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/training/finetune.cpp",
  "output": "examples/training/CMakeFiles/llama-finetune.dir/finetune.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/examples/convert-llama2c-to-ggml",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp",
  "output": "examples/convert-llama2c-to-ggml/CMakeFiles/llama-convert-llama2c-to-ggml.dir/convert-llama2c-to-ggml.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/pocs/vdot",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/pocs -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -o CMakeFiles/llama-vdot.dir/vdot.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/pocs/vdot/vdot.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/pocs/vdot/vdot.cpp",
  "output": "pocs/vdot/CMakeFiles/llama-vdot.dir/vdot.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/pocs/vdot",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/pocs -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -o CMakeFiles/llama-q8dot.dir/q8dot.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/pocs/vdot/q8dot.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/pocs/vdot/q8dot.cpp",
  "output": "pocs/vdot/CMakeFiles/llama-q8dot.dir/q8dot.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/batched-bench",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/batched-bench/batched-bench.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/batched-bench/batched-bench.cpp",
  "output": "tools/batched-bench/CMakeFiles/llama-batched-bench.dir/batched-bench.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/gguf-split",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/gguf-split/gguf-split.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/gguf-split/gguf-split.cpp",
  "output": "tools/gguf-split/CMakeFiles/llama-gguf-split.dir/gguf-split.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/imatrix",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-imatrix.dir/imatrix.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/imatrix/imatrix.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/imatrix/imatrix.cpp",
  "output": "tools/imatrix/CMakeFiles/llama-imatrix.dir/imatrix.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/llama-bench",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-bench.dir/llama-bench.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/llama-bench/llama-bench.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/llama-bench/llama-bench.cpp",
  "output": "tools/llama-bench/CMakeFiles/llama-bench.dir/llama-bench.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/main",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-cli.dir/main.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/main/main.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/main/main.cpp",
  "output": "tools/main/CMakeFiles/llama-cli.dir/main.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/perplexity",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-perplexity.dir/perplexity.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/perplexity/perplexity.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/perplexity/perplexity.cpp",
  "output": "tools/perplexity/CMakeFiles/llama-perplexity.dir/perplexity.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/quantize",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/quantize/../../common -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-quantize.dir/quantize.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/quantize/quantize.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/quantize/quantize.cpp",
  "output": "tools/quantize/CMakeFiles/llama-quantize.dir/quantize.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/server",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/server -I/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/server -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/server/../llava -I/home/strongwatchman/AI_Assistant/llama.cpp -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/. -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-server.dir/server.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/server/server.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/server/server.cpp",
  "output": "tools/server/CMakeFiles/llama-server.dir/server.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/run",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-run.dir/run.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/run/run.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/run/run.cpp",
  "output": "tools/run/CMakeFiles/llama-run.dir/run.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/run",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/run/linenoise.cpp/linenoise.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/run/linenoise.cpp/linenoise.cpp",
  "output": "tools/run/CMakeFiles/llama-run.dir/linenoise.cpp/linenoise.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/tokenize",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-tokenize.dir/tokenize.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/tokenize/tokenize.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/tokenize/tokenize.cpp",
  "output": "tools/tokenize/CMakeFiles/llama-tokenize.dir/tokenize.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/tts",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-tts.dir/tts.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/tts/tts.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/tts/tts.cpp",
  "output": "tools/tts/CMakeFiles/llama-tts.dir/tts.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/mtmd",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dmtmd_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/. -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/../.. -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/../../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-cast-qual -o CMakeFiles/mtmd.dir/mtmd.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/mtmd.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/mtmd.cpp",
  "output": "tools/mtmd/CMakeFiles/mtmd.dir/mtmd.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/mtmd",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dmtmd_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/. -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/../.. -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/../../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-cast-qual -o CMakeFiles/mtmd.dir/mtmd-audio.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/mtmd-audio.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/mtmd-audio.cpp",
  "output": "tools/mtmd/CMakeFiles/mtmd.dir/mtmd-audio.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/mtmd",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dmtmd_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/. -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/../.. -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/../../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-cast-qual -o CMakeFiles/mtmd.dir/clip.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/clip.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/clip.cpp",
  "output": "tools/mtmd/CMakeFiles/mtmd.dir/clip.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/mtmd",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -Dmtmd_EXPORTS -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/. -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/../.. -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/../../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -Wno-cast-qual -o CMakeFiles/mtmd.dir/mtmd-helper.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/mtmd-helper.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/mtmd-helper.cpp",
  "output": "tools/mtmd/CMakeFiles/mtmd.dir/mtmd-helper.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/mtmd",
  "command": "/usr/bin/c++   -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/deprecation-warning.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/deprecation-warning.cpp",
  "output": "tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/mtmd",
  "command": "/usr/bin/c++   -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/deprecation-warning.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/deprecation-warning.cpp",
  "output": "tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/mtmd",
  "command": "/usr/bin/c++   -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/deprecation-warning.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/deprecation-warning.cpp",
  "output": "tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/mtmd",
  "command": "/usr/bin/c++   -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/deprecation-warning.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/deprecation-warning.cpp",
  "output": "tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/mtmd",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/. -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/mtmd-cli.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/mtmd/mtmd-cli.cpp",
  "output": "tools/mtmd/CMakeFiles/llama-mtmd-cli.dir/mtmd-cli.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/cvector-generator",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/cvector-generator/cvector-generator.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/cvector-generator/cvector-generator.cpp",
  "output": "tools/cvector-generator/CMakeFiles/llama-cvector-generator.dir/cvector-generator.cpp.o"
},
{
  "directory": "/home/strongwatchman/AI_Assistant/llama.cpp/build/tools/export-lora",
  "command": "/usr/bin/c++ -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_CUDA -DLLAMA_SHARED -DLLAMA_USE_CURL -I/home/strongwatchman/AI_Assistant/llama.cpp/common/. -I/home/strongwatchman/AI_Assistant/llama.cpp/common/../vendor -I/home/strongwatchman/AI_Assistant/llama.cpp/src/../include -I/home/strongwatchman/AI_Assistant/llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wextra-semi -o CMakeFiles/llama-export-lora.dir/export-lora.cpp.o -c /home/strongwatchman/AI_Assistant/llama.cpp/tools/export-lora/export-lora.cpp",
  "file": "/home/strongwatchman/AI_Assistant/llama.cpp/tools/export-lora/export-lora.cpp",
  "output": "tools/export-lora/CMakeFiles/llama-export-lora.dir/export-lora.cpp.o"
}
]