
def patch_torch_for_xtts():
    import torch
    try:
        from torch.serialization import add_safe_globals
    except Exception:
        print("[XTTS] torch.add_safe_globals not available"); return

    classes = []
    # core XTTS configs
    try:
        from TTS.tts.configs.xtts_config import XttsConfig, XttsAudioConfig, BaseTTSConfig
        classes += [XttsConfig, XttsAudioConfig, BaseTTSConfig]
    except Exception as e:
        print("[XTTS] warn import xtts_config:", e)

    # dataset config
    try:
        from TTS.config.shared_configs import BaseDatasetConfig
        classes += [BaseDatasetConfig]
    except Exception as e:
        print("[XTTS] warn import BaseDatasetConfig:", e)

    # **new**: args struct that’s tripping the loader now
    try:
        from TTS.tts.models.xtts import XttsArgs
        classes += [XttsArgs]
    except Exception as e:
        print("[XTTS] warn import XttsArgs:", e)

    try:
        add_safe_globals(classes)
        print("[XTTS] Added safe_globals: " + ", ".join(c.__name__ for c in classes))
    except Exception as e:
        print("[XTTS] add_safe_globals failed:", e)

    # fallback for torch.load(weights_only=True) — retry with weights_only=False
    try:
        import TTS.utils.io as io_mod
        orig = io_mod.load_fsspec
        def load_fsspec_patched(path, map_location=None, **kwargs):
            try:
                return orig(path, map_location=map_location, **kwargs)
            except Exception:
                # last-resort, only if safe_globals didn’t cover everything
                return torch.load(path, map_location=(map_location or torch.device("cpu")), weights_only=False)
        io_mod.load_fsspec = load_fsspec_patched
        print("[XTTS] Enabled permissive load_fsspec fallback")
    except Exception as e:
        print("[XTTS] could not patch load_fsspec:", e)
