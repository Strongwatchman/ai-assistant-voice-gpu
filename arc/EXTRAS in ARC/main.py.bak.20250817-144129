#!/usr/bin/env python3
# ARC/ARK Voice Assistant â€“ console launcher (VRAM-friendly)

import os, sys, time, threading, subprocess, traceback
from pathlib import Path

# --- Make sure we can import "arc.*" even when running "python arc/main.py"
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))

# --- Environment defaults (voice stack on 3050, avatar on 2060) ---
os.environ.setdefault("CUDA_DEVICE_ORDER", "PCI_BUS_ID")
ASSISTANT_CUDA = os.environ.get("ASSISTANT_CUDA", "0")  # 3050 by default
AVATAR_CUDA    = os.environ.get("AVATAR_CUDA",    "1")  # 2060 by default
# Limit THIS process to the assistant GPU; avatar will run in a subprocess with AVATAR_CUDA
os.environ.setdefault("CUDA_VISIBLE_DEVICES", ASSISTANT_CUDA)

COMFY_URL   = os.environ.get("COMFY_URL", "http://127.0.0.1:8189")
ASSETS_DIR  = Path(os.environ.get("ARC_ASSETS", str(PROJECT_ROOT / "assets"))).expanduser()
PORTRAIT    = Path(os.environ.get("ARC_AVATAR", str(ASSETS_DIR / "portrait.png"))).expanduser()
ANIMATE_ON  = os.environ.get("ARC_ANIMATE", "0") == "1"   # default OFF
ENHANCER    = os.environ.get("ARC_ENHANCER", "gfpgan")    # or 'none'
LAST_TTS    = Path(os.environ.get("ARC_LAST_TTS", str(ASSETS_DIR / "last_tts.wav"))).expanduser()

LOG_DIR     = PROJECT_ROOT / "logs"
LOG_DIR.mkdir(parents=True, exist_ok=True)

# --- Lazy imports (avoid touching GPU/large libs at startup) ---
_audio = _stt = _cfg = _speak = _route = _choose_model = _choose_voice = _voice_test = _toggle_xtts = _init_xtts = None

def _lazy_import_assistant():
    global _audio, _stt, _cfg, _speak, _route, _choose_model, _choose_voice, _voice_test, _toggle_xtts, _init_xtts
    if _audio is None:
        from arc.audio import record_audio as _audio
        from arc.transcriber import transcribe as _stt
        from arc.config import load_settings as _cfg
        from arc.voice_handler import speak as _speak
        from arc.arc_core import route_prompt as _route
        from arc.model_selector import choose_model as _choose_model
        from arc.voice_selector import choose_voice as _choose_voice, test_voice as _voice_test, toggle_xtts_clone as _toggle_xtts
        from arc.state import init_xtts_model as _init_xtts

# --- Small helpers ---
def _open_file(path: str):
    try:
        if path and (os.environ.get("DISPLAY") or os.environ.get("WAYLAND_DISPLAY")):
            subprocess.Popen(["xdg-open", path], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    except Exception:
        pass

def _speak_async(text: str, delay: float = 0.0):
    def _run():
        if delay: time.sleep(delay)
        try:
            _speak(text)
        except Exception:
            pass
    threading.Thread(target=_run, daemon=True).start()

def _clean_gpu():
    try:
        import torch, gc
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    except Exception:
        pass

def _print_help():
    print(
"""
=========== ARC / ARK KEYS ===========

VOICE (priority 1: 3050)
  Enter  â€“ record â†’ STT â†’ LLM â†’ TTS
  T      â€“ type a message instead of recording
  C      â€“ choose TTS voice
  V      â€“ voice test
  X      â€“ toggle XTTS cloning on/off
  M      â€“ choose/switch LLM/model
  H      â€“ this help
  Q      â€“ quit

IMAGES (priority 2: 2060)
  I      â€“ ComfyUI txt2img (prompt asked inline)

SEED-WALK (priority 3: 2060)
  W      â€“ Seed-walk short video (prompt asked inline)

AVATAR ANIMATION (priority 4: 2060, heavy)
  A      â€“ toggle animate TTS replies (current: {})
  P      â€“ set/change portrait image path
  E      â€“ face enhancer: cycle gfpgan â†” none (current: {})
  O      â€“ open latest outputs (image/video)

STATUS & UTIL
  D      â€“ diagnostics (VRAM, COMFY ping, paths)
  R      â€“ reload settings
  S      â€“ save session log

""".format("ON" if state["animate"] else "OFF", state["enhancer"].upper())
    )

# --- State ---
state = {
    "animate": ANIMATE_ON,
    "enhancer": ENHANCER,  # 'gfpgan' or 'none'
    "portrait": str(PORTRAIT),
    "last_tts": str(LAST_TTS),
    "settings": {},
}

# --- ComfyUI helpers (lazy import) ---
def comfy_ping():
    try:
        from arc.comfy_client import comfy_ping as _ping
        return _ping(COMFY_URL)
    except Exception:
        return False

def comfy_txt2img_inline():
    try:
        prompt = input("ğŸ“ txt2img prompt: ").strip()
        if not prompt:
            print("âš ï¸  Empty prompt.")
            return
        from arc.comfy_client import build_txt2img_prompt, queue_and_wait
        payload = build_txt2img_prompt(
            prompt=prompt,
            width=640, height=448,   # conservative for 6GB
            steps=20, cfg=7.0,
            sampler="euler", scheduler="normal",
        )
        outs = queue_and_wait(payload, comfy_url=COMFY_URL)
        if outs:
            print(f"ğŸ–¼  Saved â†’ {outs[0]}")
            _open_file(outs[0])
        else:
            print("âš ï¸  ComfyUI finished but returned no output.")
    except Exception as e:
        print(f"âŒ Comfy txt2img error: {e}")

def comfy_seedwalk_inline():
    try:
        prompt = input("ğŸ“ seed-walk prompt: ").strip()
        if not prompt:
            print("âš ï¸  Empty prompt.")
            return
        from arc.comfy_client import txt2img_seed_walk_to_video
        mp4, frames_dir = txt2img_seed_walk_to_video(
            prompt=prompt,
            seconds=8, fps=12,
            width=640, height=448,
            steps=20, cfg=7.0,
            sampler="euler", scheduler="normal",
            seed_start=int(time.time()) % 100000,
            out_name="seedwalk",
            comfy_url=COMFY_URL
        )
        print(f"ğŸ  ComfyUI video â†’ {mp4}\nğŸ—‚  Frames â†’ {frames_dir}")
        _open_file(mp4)
    except Exception as e:
        print(f"âŒ Seed-walk error: {e}")

# --- SadTalker bridge (run in its own process on AVATAR_CUDA) ---
def sadtalker_home():
    return str(PROJECT_ROOT / "SadTalker")

def animate_avatar(audio_wav: str, portrait_path: str, enhancer: str = "gfpgan"):
    audio = Path(audio_wav).expanduser()
    pic   = Path(portrait_path).expanduser()
    if not audio.is_file():
        print(f"âš ï¸  last TTS not found: {audio}")
        return
    if not pic.is_file():
        print(f"âš ï¸  portrait not found: {pic}")
        return

    home = sadtalker_home()
    if not Path(home, "inference.py").exists():
        print(f"âš ï¸  SadTalker not found at {home}")
        return

    env = os.environ.copy()
    env["CUDA_VISIBLE_DEVICES"] = AVATAR_CUDA
    env.setdefault("PYTORCH_CUDA_ALLOC_CONF", "expandable_segments:True")

    out_dir = Path(home, "outputs_arc")
    out_dir.mkdir(parents=True, exist_ok=True)

    cmd = [
        sys.executable, "inference.py",
        "--driven_audio", str(audio),
        "--source_image", str(pic),
        "--preprocess", "full",
        "--enhancer", enhancer if enhancer in ("gfpgan", "none") else "gfpgan",
        "--result_dir", str(out_dir),
    ]
    print(f"ğŸ¬ SadTalker: {Path(audio).name} + {Path(pic).name}  â†’  {out_dir}  [GPU {AVATAR_CUDA}]")
    try:
        subprocess.run(cmd, cwd=home, env=env, check=True)
        latest = sorted(out_dir.rglob("*.mp4"), key=lambda p: p.stat().st_mtime, reverse=True)
        if latest:
            print(f"âœ… Video â†’ {latest[0]}")
            _open_file(str(latest[0]))
    except subprocess.CalledProcessError as e:
        print(f"âŒ SadTalker failed (exit {e.returncode})")
    except Exception as e:
        print(f"âŒ SadTalker error: {e}")

# --- Operator flow ---
def initialize():
    _lazy_import_assistant()
    print("ğŸ§¹ Initializing assistantâ€¦")
    _clean_gpu()
    try:
        _init_xtts()
    except Exception:
        pass

    try:
        state["settings"] = _cfg()
    except Exception:
        state["settings"] = {}

    print("\nâœ… Voice Assistant Ready.")
    print("ğŸ”˜ Press Enter to speak | T = type | H = help")
    print("ğŸ›  Animate:", "ON" if state["animate"] else "OFF", "| Enhancer:", state["enhancer"])
    print("ğŸ–¼  Portrait:", state["portrait"])
    print("ğŸ§  Devices -> ASSISTANT_CUDA:", ASSISTANT_CUDA, "| AVATAR_CUDA:", AVATAR_CUDA)
    print("âŒ Q to quit\n")

def diagnostics():
    print("\n--- Diagnostics ---")
    try:
        import torch
        g = torch.cuda.is_available()
        n = torch.cuda.device_count() if g else 0
        print(f"PyTorch CUDA: {g}, devices: {n}")
        if g:
            for i in range(n):
                name = torch.cuda.get_device_name(i)
                mem  = torch.cuda.mem_get_info(i)
                free = mem[0]/(1024**3); total = mem[1]/(1024**3)
                print(f"  GPU{i}: {name} | free {free:.2f} GiB / {total:.2f} GiB")
    except Exception as e:
        print("Torch check failed:", e)
    print("COMFY_URL:", COMFY_URL, "| ping:", comfy_ping())
    print("Assets dir:", ASSETS_DIR)
    print("Portrait:", state["portrait"])
    print("Last TTS:", state["last_tts"])
    print("Animate:", state["animate"], "| Enhancer:", state["enhancer"])
    print("---\n")

def save_session_log():
    logf = LOG_DIR / f"session_{int(time.time())}.log"
    try:
        with open(logf, "w") as f:
            f.write(f"COMFY_URL={COMFY_URL}\n")
            f.write(f"ASSISTANT_CUDA={ASSISTANT_CUDA} AVATAR_CUDA={AVATAR_CUDA}\n")
            f.write(f"ASSETS_DIR={ASSETS_DIR}\nPORTRAIT={state['portrait']}\n")
            f.write(f"ANIMATE={state['animate']} ENHANCER={state['enhancer']}\n")
        print("ğŸ“ Saved", logf)
    except Exception as e:
        print("âš ï¸  Could not save log:", e)

def open_latest_outputs():
    cands = [
        Path(sadtalker_home(), "outputs_arc"),
        PROJECT_ROOT / "ComfyUI" / "output",
    ]
    newest = None
    for base in cands:
        if not base.exists(): continue
        for p in base.rglob("*"):
            if p.is_file():
                if not newest or p.stat().st_mtime > newest.stat().st_mtime:
                    newest = p
    if newest:
        print("ğŸ—‚  Opening", newest)
        _open_file(str(newest))
    else:
        print("âš ï¸  No outputs found yet.")

def assistant_loop():
    initialize()
    while True:
        try:
            user = input("ğŸŸ¢ Your turn: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ Exiting.")
            break

        if not user:
            try:
                _audio("input.wav")
                text = _stt("input.wav")
            except Exception as e:
                print(f"âŒ Transcription failed: {e}")
                continue
            if not text:
                print("âš ï¸  No speech detected.")
                continue
            print(f"ğŸ—£ï¸ You said: {text}")
            try:
                reply = _route(text) or ""
                print(f"\nğŸ¤– IGOR:\n{reply.strip()}\n")
                _speak(reply)
                if state["animate"]:
                    animate_avatar(state["last_tts"], state["portrait"], state["enhancer"])
            except Exception as e:
                print(f"âŒ Assistant error: {e}")
            finally:
                _clean_gpu()
            continue

        key = user.strip().lower()
        if key == "q":
            print("ğŸ‘‹ Exiting.")
            break
        elif key == "h":
            _print_help()
        elif key == "t":
            typed = input("ğŸ“ Type: ").strip()
            if not typed:
                print("âš ï¸  Empty.")
                continue
            try:
                reply = _route(typed) or ""
                print(f"\nğŸ¤– IGOR:\n{reply.strip()}\n")
                _speak(reply)
                if state["animate"]:
                    animate_avatar(state["last_tts"], state["portrait"], state["enhancer"])
            except Exception as e:
                print(f"âŒ Assistant error: {e}")
            finally:
                _clean_gpu()
        elif key == "c":
            try: _choose_voice()
            except Exception as e: print("âš ï¸", e)
        elif key == "v":
            try: _voice_test()
            except Exception as e: print("âš ï¸", e)
        elif key == "x":
            try: _toggle_xtts()
            except Exception as e: print("âš ï¸", e)
        elif key == "m":
            try: _choose_model()
            except Exception as e: print("âš ï¸", e)

        elif key == "i":
            if not comfy_ping():
                print("âŒ ComfyUI not reachable on 8189. Start your tmux session.")
            else:
                comfy_txt2img_inline()
        elif key == "w":
            if not comfy_ping():
                print("âŒ ComfyUI not reachable on 8189. Start your tmux session.")
            else:
                comfy_seedwalk_inline()

        elif key == "a":
            state["animate"] = not state["animate"]
            print("ğŸ¬ Animate replies:", "ON" if state["animate"] else "OFF")
        elif key == "p":
            newp = input(f"ğŸ–¼  Portrait path [{state['portrait']}]: ").strip() or state["portrait"]
            if Path(newp).expanduser().is_file():
                state["portrait"] = newp
                print("âœ… Portrait set:", state["portrait"])
            else:
                print("âš ï¸  Not a file:", newp)
        elif key == "e":
            state["enhancer"] = "none" if state["enhancer"] == "gfpgan" else "gfpgan"
            print("âœ¨ Enhancer:", state["enhancer"].upper())
        elif key == "o":
            open_latest_outputs()

        elif key == "d":
            diagnostics()
        elif key == "r":
            try:
                state["settings"] = _cfg()
                print("ğŸ”„ Settings reloaded.")
            except Exception as e:
                print("âš ï¸  Reload failed:", e)
        elif key == "s":
            save_session_log()
        else:
            try:
                reply = _route(user) or ""
                print(f"\nğŸ¤– IGOR:\n{reply.strip()}\n")
                _speak(reply)
                if state["animate"]:
                    animate_avatar(state["last_tts"], state["portrait"], state["enhancer"])
            except Exception as e:
                print(f"âŒ Assistant error: {e}")
            finally:
                _clean_gpu()

if __name__ == "__main__":
    try:
        pkg_dir = PROJECT_ROOT / "arc"
        init_py = pkg_dir / "__init__.py"
        if pkg_dir.exists() and not init_py.exists():
            try: init_py.touch()
            except Exception: pass

        assistant_loop()
    except Exception:
        print("\nâŒ Critical failure:")
        traceback.print_exc()
